{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrapes all movies from www.boxofficemojo.com/alltime/domestic and pickles for further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pickle\n",
    "import time\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_all_movies():\n",
    "    \"\"\" Returns a list of all the movie urls from www.boxofficemojo.com/alltime/domestic\"\"\"\n",
    "    urls = [] \n",
    "    max_p = 141  # maximum page number\n",
    "    p = 0        # numbering starts at 1\n",
    "    \n",
    "    while True:\n",
    "        p += 1\n",
    "        if p > max_p:\n",
    "            break\n",
    "            \n",
    "        url = \"http://www.boxofficemojo.com/alltime/domestic.htm?page=%s&p=.htm\" % p\n",
    "        \n",
    "        try:\n",
    "            page = urllib2.urlopen(url)\n",
    "            soup = BeautifulSoup(page,'html.parser')\n",
    "            movie_urls = (soup.find(id='body').find_all('table')[1].\n",
    "                          find_all(\"a\", attrs={'href': re.compile('/movies/?')}))\n",
    "            \n",
    "            # include only first release (id=movie_title)\n",
    "            for i in movie_urls:\n",
    "                if 'page=releases&' in i['href']:\n",
    "                    movie_url = i['href'].replace('page=releases&','')\n",
    "                else:\n",
    "                    movie_url = i['href']\n",
    "                # do not include duplicates\n",
    "                if movie_url not in urls:\n",
    "                    urls.append(movie_url)\n",
    "            \n",
    "        except Exception:\n",
    "            pass\n",
    "        \n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_url(m_url):\n",
    "    \"\"\" Returns url for each movie \"\"\"\n",
    "    \n",
    "    base_url = 'http://www.boxofficemojo.com'\n",
    "    return base_url + m_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_movie_value(soup,field_name):\n",
    "    \"\"\" Takes an attribute of a movie \n",
    "    and returns string of the next sibling object\"\"\"\n",
    "    \n",
    "    try:\n",
    "        obj = soup.find(text= re.compile(field_name))\n",
    "        if not object:\n",
    "            return None\n",
    "        next_sibling = obj.findNextSibling()\n",
    "        if next_sibling:\n",
    "            return next_sibling.text\n",
    "    except AttributeError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_title(soup):\n",
    "    \"\"\" Return title\"\"\"\n",
    "    \n",
    "    try:\n",
    "        title = soup.find(\"title\").text.split(\"-\")[0].strip()\n",
    "        return title\n",
    "    \n",
    "    except AttributeError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_grosses(soup,gross):\n",
    "    \"\"\" Return Total Lifetime Gross/ Opening Weekend Gross as float or ignore if missing \"\"\"\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        if gross == 'TLG':\n",
    "            gross = (soup.find_all(class_ = 'mp_box_content')[0].find_all('tr')[0].find_all('td')[1]).text\n",
    "        else:\n",
    "            gross = (soup.find_all(class_ = 'mp_box_content')[1].find_all('tr')[0].find_all('td')[1]).text\n",
    "     \n",
    "\n",
    "        if gross and \"$\" in gross:\n",
    "            return float(gross.replace(\"$\",\"\").replace(\",\",\"\"))\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    except Exception:\n",
    "        pass\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def opening_theaters(soup):\n",
    "    \"\"\"Return string containing info on opening weekend theaters or ignore if missing\"\"\"\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        open_stuff = soup.find_all(class_ = 'mp_box_content')[1].find_all('tr')[1].find_all('td')[0].text\n",
    "        return open_stuff\n",
    "    \n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def players(soup,player):\n",
    "    \"\"\" Return a list of players, e.g., actors, directors, etc.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        players = soup.find_all('a', attrs={'href' : re.compile(\"/people/chart/[?]view=%s\" %  player)}) \n",
    "        \n",
    "        player_name=[]\n",
    "        for _ in players:\n",
    "            player_name.append(_.text.strip('*'))\n",
    "        return player_name\n",
    "    \n",
    "    except AttributeError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Events processed 0\n",
      "Events processed 100\n",
      "Events processed 200\n",
      "Events processed 300\n",
      "Events processed 400\n",
      "Events processed 500\n",
      "Events processed 600\n",
      "Events processed 700\n",
      "Events processed 800\n",
      "Events processed 900\n",
      "Events processed 1000\n",
      "Events processed 1100\n",
      "Events processed 1200\n",
      "Events processed 1300\n",
      "Events processed 1400\n",
      "Events processed 1500\n",
      "Events processed 1600\n",
      "Events processed 1700\n",
      "Events processed 1800\n",
      "Events processed 1900\n",
      "Events processed 2000\n",
      "Events processed 2100\n",
      "Events processed 2200\n",
      "Events processed 2300\n",
      "Events processed 2400\n",
      "Events processed 2500\n",
      "Events processed 2600\n",
      "Events processed 2700\n",
      "Events processed 2800\n",
      "Events processed 2900\n",
      "Events processed 3000\n",
      "Events processed 3100\n",
      "Events processed 3200\n",
      "Events processed 3300\n",
      "Events processed 3400\n",
      "Events processed 3500\n",
      "Events processed 3600\n",
      "Events processed 3700\n",
      "Events processed 3800\n",
      "Events processed 3900\n",
      "Events processed 4000\n",
      "Events processed 4100\n",
      "Events processed 4200\n",
      "Events processed 4300\n",
      "Events processed 4400\n",
      "Events processed 4500\n",
      "Events processed 4600\n",
      "Events processed 4700\n",
      "Events processed 4800\n",
      "Events processed 4900\n",
      "Events processed 5000\n",
      "Events processed 5100\n",
      "Events processed 5200\n",
      "Events processed 5300\n",
      "Events processed 5400\n",
      "Events processed 5500\n",
      "Events processed 5600\n",
      "Events processed 5700\n",
      "Events processed 5800\n",
      "Events processed 5900\n",
      "Events processed 6000\n",
      "Events processed 6100\n",
      "Events processed 6200\n",
      "Events processed 6300\n",
      "Events processed 6400\n",
      "Events processed 6500\n",
      "Events processed 6600\n",
      "Events processed 6700\n",
      "Events processed 6800\n",
      "Events processed 6900\n",
      "Events processed 7000\n",
      "Events processed 7100\n",
      "Events processed 7200\n",
      "Events processed 7300\n",
      "Events processed 7400\n",
      "Events processed 7500\n",
      "Events processed 7600\n",
      "Events processed 7700\n",
      "Events processed 7800\n",
      "Events processed 7900\n",
      "Events processed 8000\n",
      "Events processed 8100\n",
      "Events processed 8200\n",
      "Events processed 8300\n",
      "Events processed 8400\n",
      "Events processed 8500\n",
      "Events processed 8600\n",
      "Events processed 8700\n",
      "Events processed 8800\n",
      "Events processed 8900\n",
      "Events processed 9000\n",
      "Events processed 9100\n",
      "Events processed 9200\n",
      "Events processed 9300\n",
      "Events processed 9400\n",
      "Events processed 9500\n",
      "Events processed 9600\n",
      "Events processed 9700\n",
      "Events processed 9800\n",
      "Events processed 9900\n",
      "Events processed 10000\n",
      "Events processed 10100\n",
      "Events processed 10200\n",
      "Events processed 10300\n",
      "Events processed 10400\n",
      "Events processed 10500\n",
      "Events processed 10600\n",
      "Events processed 10700\n",
      "Events processed 10800\n",
      "Events processed 10900\n",
      "Events processed 11000\n",
      "Events processed 11100\n",
      "Events processed 11200\n",
      "Events processed 11300\n",
      "Events processed 11400\n",
      "Events processed 11500\n",
      "Events processed 11600\n",
      "Events processed 11700\n",
      "Events processed 11800\n",
      "Events processed 11900\n",
      "Events processed 12000\n",
      "Events processed 12100\n",
      "Events processed 12200\n",
      "Events processed 12300\n",
      "Events processed 12400\n",
      "Events processed 12500\n",
      "Events processed 12600\n",
      "Events processed 12700\n",
      "Events processed 12800\n",
      "Events processed 12900\n",
      "Events processed 13000\n",
      "Events processed 13100\n",
      "Events processed 13200\n",
      "Events processed 13300\n",
      "Events processed 13400\n",
      "Events processed 13500\n",
      "Events processed 13600\n",
      "Events processed 13700\n",
      "Events processed 13800\n",
      "Events processed 13900\n",
      "Events processed 14000\n"
     ]
    }
   ],
   "source": [
    "all_movies = []\n",
    "\n",
    "for num, i in enumerate(urls):\n",
    "    try:\n",
    "        data = {} # dictionary \n",
    "        url_m = get_url(i)\n",
    "        page_m = urllib2.urlopen(url_m)\n",
    "        soup_m = BeautifulSoup(page_m,'html.parser')\n",
    "    \n",
    "        data['title'] = get_title(soup_m)\n",
    "    \n",
    "        tab1 = ['Domestic Total', 'Distributor', 'Genre:', 'MPAA Rating', 'Release Date',\\\n",
    "                'Runtime', 'Production Budget']\n",
    "        for _ in tab1:\n",
    "            data[_] = get_movie_value(soup_m,_)\n",
    "        \n",
    "        grosses = ['TLG', 'openWDG']    \n",
    "        for gross in grosses:\n",
    "            data[gross] = get_grosses(soup_m,gross)\n",
    "        \n",
    "        \n",
    "        data['OWtheaters'] = opening_theaters(soup_m)\n",
    "    \n",
    "        cast = ['Director', 'Writer', 'Actor','Producer', 'Composer']\n",
    "        for member in cast:\n",
    "            data[member] = players(soup_m,member)\n",
    "            \n",
    "        # append dictionary to a list containing all movies    \n",
    "        all_movies.append(data)\n",
    "    \n",
    "        # add delay for scraping\n",
    "        if num % 100 == 0:\n",
    "            print 'Events processed %d' % num\n",
    "            time.sleep(10) \n",
    "        elif num % 500 == 0:\n",
    "            time.sleep(30)\n",
    "        elif num % 1000 == 0:\n",
    "            time.sleep(60)\n",
    "    \n",
    "    except Exception:\n",
    "        #logging.exception(e)\n",
    "        pass\n",
    "    \n",
    "with open('all_data.pkl', 'w') as picklefile:\n",
    "    pickle.dump(all_movies, picklefile)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14006"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"all_boxofficemojo.pkl\", 'r') as picklefile: \n",
    "    my_old_data = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of events/movies pickled = 14006\n",
      "\n",
      "Star Wars: The Force Awakens (2015)\n",
      "Avatar (2009)\n",
      "Titanic (1997)\n",
      "Jurassic World (2015)\n",
      "Marvel's The Avengers (2012)\n",
      "The Dark Knight (2008)\n",
      "Star Wars: Episode I\n",
      "Star Wars (1977)\n",
      "Avengers: Age of Ultron (2015)\n",
      "The Dark Knight Rises (2012)\n"
     ]
    }
   ],
   "source": [
    "print 'Total number of events/movies pickled = %d' %len(my_old_data)\n",
    "print\n",
    "for _ in my_old_data[:10]:\n",
    "    print _['title']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
